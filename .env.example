# Second Opinion Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# API Keys (Required)
# =============================================================================

# OpenRouter API Key (primary multi-model access)
# Get your key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Direct provider API keys for additional functionality
# Anthropic API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key  
OPENAI_API_KEY=your_openai_api_key_here

# Google AI API Key
GOOGLE_API_KEY=your_google_api_key_here

# =============================================================================
# Local Development (Optional)
# =============================================================================

# LM Studio Configuration (for local model testing)
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_API_KEY=not_needed_for_local

# =============================================================================
# Security Configuration
# =============================================================================

# Database Encryption Key (generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
DATABASE_ENCRYPTION_KEY=your_generated_encryption_key_here

# Session encryption key (different from database key)
SESSION_ENCRYPTION_KEY=your_session_encryption_key_here

# =============================================================================
# Cost and Usage Limits
# =============================================================================

# Default cost limit per request in USD (prevents runaway spending)
DEFAULT_COST_LIMIT=0.10

# Daily spending limit in USD
DAILY_COST_LIMIT=5.00

# Monthly spending limit in USD  
MONTHLY_COST_LIMIT=50.00

# Maximum tokens per request (cost control)
MAX_TOKENS_PER_REQUEST=2000

# =============================================================================
# Application Configuration
# =============================================================================

# Environment (development, staging, production)
ENVIRONMENT=development

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Data directory for local storage
DATA_DIR=./data

# Configuration directory
CONFIG_DIR=./config

# Prompts directory
PROMPTS_DIR=./prompts

# =============================================================================
# MCP Server Configuration
# =============================================================================

# MCP Server host (usually localhost for development)
MCP_SERVER_HOST=localhost

# MCP Server port
MCP_SERVER_PORT=8000

# Enable development mode (auto-reload, debug logging)
MCP_DEV_MODE=true

# =============================================================================
# Rate Limiting and Performance
# =============================================================================

# Requests per minute limit per API key
RATE_LIMIT_PER_MINUTE=60

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=5

# Request timeout in seconds
REQUEST_TIMEOUT=30

# =============================================================================
# Security Options
# =============================================================================

# Enable input sanitization (recommended: true)
ENABLE_INPUT_SANITIZATION=true

# Enable response filtering (prevent API key leakage)
ENABLE_RESPONSE_FILTERING=true

# Enable usage analytics (track model performance)
ENABLE_USAGE_ANALYTICS=true

# Minimum password/key length for validation
MIN_KEY_LENGTH=32

# =============================================================================
# Advanced Configuration
# =============================================================================

# Default model temperature
DEFAULT_TEMPERATURE=0.1

# Default model selection strategy (cheapest, balanced, premium)
DEFAULT_MODEL_STRATEGY=balanced

# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=false

# Cache duration for model responses (in seconds, 0 to disable)
RESPONSE_CACHE_DURATION=0